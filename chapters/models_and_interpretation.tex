
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\فصل{مدل‌های آنالیز بقا و تفسیر‌پذیری}

در این فصل به مدل‌هایی که آنالیز بقا را به کمک آن‌ها انجام دادیم می‌پردازیم و آن‌ها را تا حد امکان تشریح کرده و شیوه عملکردشان را شرح می‌دهیم. همچنین در در انتها، در خصوص انتخاب ویژگی‌ها و تعیین اهمیت آن‌ها صحبت می‌کنیم و ایده‌هایی که به این منظور استفاده شدند را شرح می‌دهیم. ضمناً مجموعه‌ی $D$ را مجموعه‌ی افراد فوت‌شده در داده‌هایمان تعریف می‌کنیم. برخی از توابع هزینه از این مجموعه استفاده می‌کنند.

\قسمت{\lr{Cox-PH}}
مدل آماری \lr{Cox-PH} که تابع خطر برای بیمار با بردار ویژگی‌های $x$ را در لحظه‌ی $t$ به شکل 
$$h(t|x) = h_0(t) \exp{\beta^\intercal x}$$
محاسبه می‌کند. این مدل، بردار $\beta$ را با کمینه کردن تابع جزئی لگاریتم درست‌نمایی \پاورقی{partial log likelihood} به دست می‌آورد \مرجع{r10}. همچنین یک تابع $h_0$ زمینه‌ای هم موجود است که به شکلی مستقل محاسبه شده و برای همه‌ی بیماران استفاده می‌شود.

تابع جزئی درست‌نمایی، هزینه را برای $\beta$ بدین شکل محاسبه می‌کند:
$$\mathcal{L}(\beta) = \prod_{i \in D} \frac{h_0(t_i) \exp{\beta^\intercal x_i}}{\sum_{j, t_j\geq t_i} h_0(t_i) \exp{\beta^\intercal x_j}}$$

در حقیقت تابع جزئی درست‌نمایی، برای فرد فوت شده‌ی $i$، حساب می‌کند که نسبت تابع خطرش در لحظه‌ی مرگ، به حاصل جمع تابع خطر در لحظه‌ی $t_i$ افرادی که حداقل به اندازه‌ی $i$ زنده مانده‌اند، چقدر است. توقع داریم که شانس مرگ فرد $i$ نسبت به بقیه در آن لحظه خیلی بیشتر بوده باشد و این کسر نزدیک به $1$ باشد. با ساده‌کردن عبارت فوق، تابع جزئی درست‌نمایی به صورت زیر می‌شود.

$$\mathcal{L}(\beta) = \prod_{i \in D} \frac{ \exp{\beta^\intercal x_i}}{\sum_{j, t_j\geq t_i} \exp{\beta^\intercal x_j}}$$

مدل \lr{Cox-PH} قرینه لگاریتم تابع درست‌نمایی بالا، را کمینه می‌کند. در حقیقت مسأله‌ی کمینه‌سازی زیر را حل می‌کند.
$$-\ln{\mathcal{L}(\beta)} = -\sum_{i \in D}\left[
\beta^\intercal x_i - \ln{\sum_{j, t_j\geq t_i} \exp{\beta^\intercal x_j}}
\right]$$

\قسمت{جنگل بقای تصادفی}
در این مدل، تعدادی درخت تصمیم تولید می‌شود. هر درخت تصمیم با بخشی از داده‌ها و زیرمجموعه‌ای ویژگی‌ها آموزش می‌بیند و هر گره‌اش، براساس یکی از ویژگی‌ها به دو بچه تقسیم می‌شود. معیار انتخاب ویژگی‌ و تعیین مقدار آن ویژگی برای جداسازی دو بچه، بیشینه کردن معیار تست \lr{log-rank} \پانویس{Logrank Test Statistics} است \مرجع{r17, r11}. براین اساس، در هر گره، داده‌ها به گونه‌ای به دو دسته تقسیم می‌شوند که توزیع بقا در دو دسته بیشترین اختلاف را داشته باشد. این مدل ابرپارمتر‌های گوناگونی از قبیل حداکثر عمق درخت‌ها، تعداد درخت‌ها، تعداد ویژگی‌هایی که هر درخت در نظر می‌گیرد و حداقل تعداد داده‌ها در گره‌های پایانی دارد.

\قسمت{ماشین تقویت گرادیان}
در ماشین تقویت گرادیان، برای هر بیمار یک تابع $f(x)$ به دست می‌آوریم که قرار است مشابه کارکرد $\beta^\intercal x$ در مدل \lr{Cox-PH} را داشته باشد. این مدل مقدار $f(x)$ را به کمک $M$ مدل ساده‌تر که برای رگرسیون به کار می‌روند مطابق با رابطه‌ی زیر تخمین می‌زند \مرجع{r17, r11}:
$$f(x) = \sum_{i=1}^M \beta_m g(x; \theta_m).$$

در این مدل، تابع هزینه همان تابع جزئی درستنمایی \lr{Cox} است منتها با تابع $f$. به بیان بهتر، تابع هزینه به صورت زیر تعریف می‌شود:
$$l(f) = -
\sum_{i \in D}\left[
f(x_i) - \ln{\sum_{j, t_j\geq t_i} \exp{f(x_j)}}
\right].$$

\قسمت{شبکه‌های عصبی}
در این فصل مدل‌های یادگیری عمیق استفاده می‌شوند. سه مدل
\lr{Deep Surv}
،
\lr{Logistic Hazard}
و
\lr{PC Hazard}
\مرجع{r7, r14, r15}
در این پایان‌نامه بررسی شده‌اند.

روش \lr{Deep Surv}، همان \lr{Cox-PH} است که در آن قرار است یک شبکه‌ی عصبی با پارامتر $\theta$ تابع زمینه‌ای
$h_\theta(x)$
را تخمین بزند. در حقیقت خروجی شبکه‌ی عصبی، مقدار زمینه‌ای تابع خطر باشد. بنابر این تعریف، تابع هزینه‌ی این مدل با در نظر گرفتن ضریب منظم‌ساز \پانویس{Regularization} به صورت زیر است:
$$l(\theta) = 
\frac{1}{N_{\text{dead}}}
 -\sum_{i \in D}\left[
h_\theta(x_i) - \ln{\sum_{j, t_j\geq t_i} \exp{h_\theta(x_j)}}
\right] + \lambda \norm{\theta}_{2}^{2}.
$$

روش \lr{Logistic Hazard}، تابع هزینه‌ای مطابق رابطه‌ی زیر دارد:
$$\mathcal{L} = -\frac{1}{n} \sum_{i=1}^{n} 
\left(d_i \ln{\left[
	h(t_i | x_i)\right]} + 
(1 - d_i) \ln{\left[
	1-h(t_i|x_i)\right]}+
\sum_{j, t_j < t_i} \ln{\left[
	1-h(t_j|x_i)\right]}
\right)
$$
که در رابطه‌ی فوق، $d_i$ برای بیمار $i$اُم مشخص می‌کند که مرده است ($d_i=1$) یا زنده است ($d_i=0$). این شبکه‌ی عصبی سعی می‌کند تابع خطر ($h$) را به گونه‌ای تخمین بزند که هزینه کمینه شود. این روش، تابع خطر را به شکل گسسته تخمین می‌زند و صرفا در نقاط $t_i$، این تابع برای بیماران مختلف مقدار دارد.

روش \lr{PC Hazard} مشابه روش \lr{Logistic Hazard} است، منتها تابع خطر را به شکل پیوسته تخمین می‌زند و به خاطر این موضوع، تابع هزینه‌ی متفاوتی دارد \مرجع{r8}.


\قسمت{اهمیت ویژگی‌‌ها}

یکی از کارهایی که در این در این پایان‌نامه قصد انجام آن را داشتیم، این بود که متوجه شویم کدام ویژگی‌ها اهمیت بیشتری دارند و نقش مهم‌تری در بقا ایفا می‌کنند.

به منظور استخراج این ویژگی‌ها، دو مدل جنگل تصادفی بقا و ماشین تقویت گرادیان، هر دو براساس ویژگی‌هایی درونیشان می‌توانند ضریبی برای اهمیت فیچرها استخراج کنند. در ادامه اما برای مدل \lr{Logistic Hazard} از یک ایده برای بررسی اهمیت ویژگی‌ها و انتخاب آنها استفاده کردیم. ما دو حالت جستجوی کامل \پانویس{Exhaustive Search}و جستجوی نیمه‌کامل \پانویس{Semi Exhaustive Search} را ارائه می‌دهیم که به کمک آنها می‌توان تا حدی در مورد ویژگی‌های مهم که بودنشان در آنالیز بقا اثرگذار است، اطلاعاتی کسب کنیم.

در روش جستجوی کامل، ما از $22$ ویژگی موجود، $2$ تا از ویژگی‌ها را کنار می‌گذاریم. سپس برای $20$ ویژگی باقی‌مانده از مدلمان استفاده کرده و با این ویژگی‌ها مدل را آموزش می‌دهیم. اگر به ازای همه $20$تایی‌ها از ویژگی‌ها، این آزمایش را انجام دهیم، ما تعداد
$22 \choose 2$
 آزمایش خواهیم داشت. مقدار $C_{index}$ استخراج شده برای همه‌ی این آزمایش‌ها را بررسی می‌کنیم. اگر مقدار $C_{index}$ روی داده‌ی تست برای یک $20$‌تایی از ویژگی‌ها مناسب باشد، یا به عبارت بهتر از حدی بالاتر باشد، می‌توان نتیجه گرفت که احتمالا آن $20$ ویژگی می‌توانستند شرایط بیمار را توصیف کنند و به اندازه‌ی کافی دانش در اختیار مدل قرار می‌داده‌اند. نتایج این بررسی و آنچه از آن به دست آمد در فصل بعدی قابل مشاهده است.

در روش جستجوی نیمه‌کامل، تعداد $1000$ آزمایش که در هر یک از آن‌ها یک مجموعه‌ی $15$‌تایی تصادفی از ویژگی‌ها انتخاب شده و مدل \lr{Logisistic Hazard} روی آن $15$ ویژگی آموزش می‌بیند بررسی شد. مجدداً آن مجموعه از ویژگی‌ها که بتواند معیار $C_{index}$ قابل قبولی (از حدی بالاتر) داشته باشد، به این معناست که دربرگیرنده‌ی ویژگی‌های مهم هست. در مورد نتایج این بررسی و آن ویژگی‌هایی که با این بررسی مهم تلقی شده‌اند در فصل بعدی بحث شده است.

\قسمت{جمع‌بندی}
در این فصل به معرفی مدل‌های \lr{Cox-PH}، جنگل بقای تصادفی، ماشین تقویت گرادیان، \lr{Logistic Hazard}، \lr{Deep Surv} و \lr{PC Hazard} پرداختیم و شیوه‌ی کارکرد و توابع هزینه‌ی آن‌ها را معرفی کردیم. در انتها به اهمیت ویژگی‌ها و شیوه‌هایی که اهمیت ویژگی‌ها را در مدل‌هایمان تخمین می‌زنیم پرداختیم.




